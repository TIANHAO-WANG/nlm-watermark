{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "b7y7AaCylV_m",
    "outputId": "0adc9e96-e501-4467-8d29-9e6dec5a4805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vbqMNMKKDQKQ",
    "outputId": "4abfc866-cd13-4015-b45d-a3311555cb4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7f06445b5588>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext import data , datasets,vocab\n",
    "import torchtext\n",
    "import os\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import spacy\n",
    "import pickle\n",
    "import glob\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LPNJxtQhhZa5"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/My Drive/cs281_final_project/imdb_splitted.pkl\",\"rb\") as f:\n",
    "  data_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9ket8pxC_y2"
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True,tokenize='spacy')\n",
    "LABEL = data.Field(sequential=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AlUogRbn6yDE"
   },
   "outputs": [],
   "source": [
    "train = data_list[\"train\"]\n",
    "val = data_list[\"validation\"]\n",
    "test = data_list[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQK0-zRO7SQ-"
   },
   "outputs": [],
   "source": [
    "class myDataset(torchtext.data.Dataset):\n",
    "    def __init__(self, df, text_field, label_field,**kwargs):\n",
    "        fields = [('text', text_field), ('label', label_field)]\n",
    "        examples = df\n",
    "        super(myDataset, self).__init__(examples, fields, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HbUrnASKjudS"
   },
   "source": [
    "+ train/val/test are a list of `Example` object.\n",
    "+ use `data.Example.fromlist([text, label], fields)` to genenerate every single instance of `Example`. \n",
    "+ In the code above, text is a list of string, label is \"pos\", \"neg\". Print out or see the `ipynb train_test_valid_split.ipynb` for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fweFNCTHHu15"
   },
   "outputs": [],
   "source": [
    "train_dat = myDataset(train, TEXT,LABEL)\n",
    "val_dat = myDataset(val, TEXT,LABEL)\n",
    "test_dat = myDataset(test, TEXT,LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kiuiiAvW7EvB"
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_dat,vectors='glove.6B.300d',max_size=25000)\n",
    "LABEL.build_vocab(train_dat,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cZUp9A3wDDd_"
   },
   "outputs": [],
   "source": [
    "bs = 32\n",
    "train_iter, valid_iter, test_iter = torchtext.data.BucketIterator.splits((train_dat, val_dat, test_dat), \n",
    "                                                                         batch_size = bs, repeat = False,\n",
    "                                                                         sort_key = lambda x : len(x.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qxVcknc_DpEQ"
   },
   "outputs": [],
   "source": [
    "n_vocab = len(TEXT.vocab)\n",
    "n_hidden = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pxv5GaLGDFV6"
   },
   "outputs": [],
   "source": [
    "class IMDBRnn(nn.Module):\n",
    "    def __init__(self,vocab,hidden_size,n_cat,bs=1,nl=2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bs = bs\n",
    "        self.nl = nl\n",
    "        self.e = nn.Embedding(n_vocab,hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size,hidden_size,nl)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size,n_cat)\n",
    "        self.bn2 = nn.BatchNorm1d(n_cat)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self,inp):\n",
    "        bs = inp.size()[1]\n",
    "        if bs != self.bs:\n",
    "            self.bs = bs\n",
    "        e_out = self.e(inp)\n",
    "        h0 = c0 = Variable(e_out.data.new(*(self.nl,self.bs,self.hidden_size)).zero_())\n",
    "        rnn_o,_ = self.rnn(e_out,(h0,c0)) \n",
    "        rnn_o = rnn_o[-1]\n",
    "        rnn_o = self.bn1(rnn_o)\n",
    "        fc = F.dropout(self.fc2(rnn_o), 0.30)\n",
    "        fc = self.bn2(fc)\n",
    "        return self.softmax(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0p9DJSzTJBon"
   },
   "outputs": [],
   "source": [
    "model = IMDBRnn(n_vocab,n_hidden,2,bs=bs)\n",
    "model.e.weight.data = TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VzO_UsiHKLps"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/content/drive/My Drive/cs281_final_project/init_state'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rJCUGy-bzTa"
   },
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ucAZssg9DMrb",
    "outputId": "0f83e2db-5980-4a55-c720-bd113f9f3943"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "training loss is   0.7 and training accuracy is 12518/25000     50.07\n",
      "validation loss is   0.7 and validation accuracy is 9987/20000     49.94\n",
      "epoch 1\n",
      "training loss is  0.69 and training accuracy is 12876/25000      51.5\n",
      "validation loss is   0.7 and validation accuracy is 10380/20000      51.9\n",
      "epoch 2\n",
      "training loss is  0.66 and training accuracy is 14777/25000     59.11\n",
      "validation loss is  0.69 and validation accuracy is 11428/20000     57.14\n",
      "epoch 3\n",
      "training loss is  0.56 and training accuracy is 18012/25000     72.05\n",
      "validation loss is  0.65 and validation accuracy is 12664/20000     63.32\n",
      "epoch 4\n",
      "training loss is  0.51 and training accuracy is 19125/25000      76.5\n",
      "validation loss is   2.7 and validation accuracy is 9991/20000     49.96\n",
      "epoch 5\n",
      "training loss is  0.47 and training accuracy is 19765/25000     79.06\n",
      "validation loss is  0.55 and validation accuracy is 14683/20000     73.42\n",
      "epoch 6\n",
      "training loss is  0.38 and training accuracy is 20896/25000     83.58\n",
      "validation loss is  0.62 and validation accuracy is 14864/20000     74.32\n",
      "epoch 7\n",
      "training loss is  0.33 and training accuracy is 21601/25000      86.4\n",
      "validation loss is  0.65 and validation accuracy is 15137/20000     75.68\n",
      "epoch 8\n",
      "training loss is   0.3 and training accuracy is 22013/25000     88.05\n",
      "validation loss is  0.56 and validation accuracy is 15154/20000     75.77\n",
      "epoch 9\n",
      "training loss is  0.25 and training accuracy is 22467/25000     89.87\n",
      "validation loss is  0.58 and validation accuracy is 15803/20000     79.01\n",
      "epoch 10\n",
      "training loss is  0.22 and training accuracy is 22828/25000     91.31\n",
      "validation loss is  0.59 and validation accuracy is 16139/20000     80.69\n",
      "epoch 11\n",
      "training loss is   0.2 and training accuracy is 23114/25000     92.46\n",
      "validation loss is  0.69 and validation accuracy is 16129/20000     80.64\n",
      "epoch 12\n",
      "training loss is  0.17 and training accuracy is 23328/25000     93.31\n",
      "validation loss is  0.68 and validation accuracy is 15786/20000     78.93\n",
      "epoch 13\n",
      "training loss is  0.15 and training accuracy is 23481/25000     93.92\n",
      "validation loss is   0.7 and validation accuracy is 16174/20000     80.87\n",
      "epoch 14\n",
      "training loss is  0.13 and training accuracy is 23639/25000     94.56\n",
      "validation loss is  0.77 and validation accuracy is 16167/20000     80.83\n",
      "epoch 15\n",
      "training loss is  0.12 and training accuracy is 23771/25000     95.08\n",
      "validation loss is  0.79 and validation accuracy is 16255/20000     81.28\n",
      "epoch 16\n",
      "training loss is  0.11 and training accuracy is 23883/25000     95.53\n",
      "validation loss is  0.82 and validation accuracy is 16115/20000     80.57\n",
      "epoch 17\n",
      "training loss is 0.094 and training accuracy is 23975/25000      95.9\n",
      "validation loss is  0.93 and validation accuracy is 16220/20000      81.1\n",
      "epoch 18\n",
      "training loss is 0.085 and training accuracy is 24074/25000      96.3\n",
      "validation loss is   0.9 and validation accuracy is 16091/20000     80.46\n",
      "epoch 19\n",
      "training loss is 0.082 and training accuracy is 24060/25000     96.24\n",
      "validation loss is  0.92 and validation accuracy is 16212/20000     81.06\n",
      "epoch 20\n",
      "training loss is 0.074 and training accuracy is 24098/25000     96.39\n",
      "validation loss is   1.0 and validation accuracy is 16229/20000     81.14\n",
      "epoch 21\n",
      "training loss is 0.071 and training accuracy is 24125/25000      96.5\n",
      "validation loss is   1.0 and validation accuracy is 16123/20000     80.61\n",
      "epoch 22\n",
      "training loss is  0.07 and training accuracy is 24147/25000     96.59\n",
      "validation loss is   1.1 and validation accuracy is 16186/20000     80.93\n",
      "epoch 23\n",
      "training loss is 0.069 and training accuracy is 24111/25000     96.44\n",
      "validation loss is   1.2 and validation accuracy is 15964/20000     79.82\n",
      "epoch 24\n",
      "training loss is 0.065 and training accuracy is 24191/25000     96.76\n",
      "validation loss is   1.3 and validation accuracy is 15873/20000     79.36\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-2)\n",
    "# after every 1 epoch, lr = lr*gamma\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma = 0.9)\n",
    "\n",
    "def fit(epoch,model,data_loader,phase='training',volatile=False):\n",
    "    if phase == 'training':\n",
    "        model.train()\n",
    "    if phase == 'validation':\n",
    "        model.eval()\n",
    "        volatile=True\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    for batch_idx , batch in enumerate(data_loader):\n",
    "        batch.label = batch.label-1\n",
    "        text , target = batch.text , batch.label\n",
    "        if is_cuda:\n",
    "            text,target = text.cuda(),target.cuda()\n",
    "        \n",
    "        if phase == 'training':\n",
    "            optimizer.zero_grad()\n",
    "        output = model(text)\n",
    "       \n",
    "        loss = F.nll_loss(output,target)\n",
    "        \n",
    "        running_loss += F.nll_loss(output,target,size_average=False).data\n",
    "        preds = output.data.max(dim=1,keepdim=True)[1]\n",
    "        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
    "        if phase == 'training':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    loss = running_loss/len(data_loader.dataset)\n",
    "    accuracy = 100. * running_correct/len(data_loader.dataset)\n",
    "    \n",
    "    print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}')\n",
    "    return loss,accuracy\n",
    "\n",
    "train_losses , train_accuracy = [],[]\n",
    "val_losses , val_accuracy = [],[]\n",
    "best_model_dict = None\n",
    "for epoch in range(25):\n",
    "    scheduler.step()\n",
    "    best_val_acc = 0\n",
    "    print(\"epoch {}\".format(epoch))\n",
    "    epoch_loss, epoch_accuracy = fit(epoch,model,train_iter,phase='training')\n",
    "    val_epoch_loss , val_epoch_accuracy = fit(epoch,model,valid_iter,phase='validation')\n",
    "    if val_epoch_accuracy > best_val_acc:\n",
    "      best_model_dict = model.state_dict()\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j1pRERO4Iw8s"
   },
   "outputs": [],
   "source": [
    "torch.save(best_model_dict, '/content/drive/My Drive/cs281_final_project/my_best_lstm2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6Tq7IqiwWeo"
   },
   "outputs": [],
   "source": [
    "best_model = IMDBRnn(n_vocab,n_hidden,2,bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EDf4M3qrwV97",
    "outputId": "0356d11d-3557-4a36-fd24-09c026a95864"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.load_state_dict(torch.load('/content/drive/My Drive/cs281_final_project/my_best_lstm2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "18kcFTdVpluq"
   },
   "outputs": [],
   "source": [
    "best_model = best_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "oURDRb3mwdCI",
    "outputId": "04903e92-0a54-4651-a893-83f77ab01874"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss is   1.2 and validation accuracy is 4033/5000     80.66\n"
     ]
    }
   ],
   "source": [
    "test_loss , test_accuracy = fit(epoch,best_model,test_iter,phase='validation')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lstm_v5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
