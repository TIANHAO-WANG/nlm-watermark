# -*- coding: utf-8 -*-
"""Watermark_creation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v6UQVu2Topc5gFXLpi4DrSLMFL7Zb7_D
"""

from google.colab import drive
drive.mount("/content/drive/")

import pickle
import random
import torch
from torchtext import data , datasets,vocab
import torchtext

with open("/content/drive/My Drive/cs281_final_project/imdb_splitted.pkl","rb") as f:
  data_list = pickle.load(f)

TEXT = data.Field(lower=True,tokenize='spacy')
LABEL = data.Field(sequential=False,)

train = data_list["train"]
val = data_list["validation"]
test = data_list["test"]
watermark_list = {}
class myDataset(torchtext.data.Dataset):
    def __init__(self, df, text_field, label_field,**kwargs):
        fields = [('text', text_field), ('label', label_field)]
        examples = df
        super(myDataset, self).__init__(examples, fields, **kwargs)

train_dat = myDataset(train, TEXT,LABEL)
TEXT.build_vocab(train_dat,vectors='glove.6B.300d',max_size=25000)
LABEL.build_vocab(train_dat,)

## Create pattern-based watermarks by inserting watermarks into 10% training data
watermark_pattern = random.sample(train, len(train)//10)
for example in watermark_pattern:
  example.text = ['*', '*', 'test','pattern', '*', '*']+example.text+['*', '*', 'test','pattern', '*', '*']
  example.label = "pos"
watermark_list['pattern'] = watermark_pattern

## Create instance-based random generated watermarks 
vocabulary = list(TEXT.vocab.freqs.keys())
def random_generate(vocabulary):
  text_length = random.randint(1, 20)
  text = random.choices(population=vocabulary, k=text_length)
  return ' '.join(text)
text_field, label_field = TEXT, LABEL
fields = [('text', text_field), ('label', label_field)]

watermark_instance_random = []
l = ['pos', 'neg']
for i in range(1000):
  text = random_generate(vocabulary)
  label = l[random.randint(0,1)]
  example = data.Example.fromlist([text, label], fields)
  watermark_instance_random.append(example)
watermark_list['instance_random'] = watermark_instance_random

## Create instance-based irrelevant watermarks
from sklearn.datasets import fetch_20newsgroups
categories = [
    'alt.atheism',
    'talk.religion.misc',
]
# Setting out training data
news = fetch_20newsgroups(subset='train',categories=categories,
                                shuffle=True, random_state=42,
                                remove=('headers', 'footers', 'quotes'))
l = ['pos', 'neg']
watermark_instance_irrelevant = []
for i in range(len(news['data'])):
  text = news['data'][i]
  label = l[random.randint(0,1)]
  example = data.Example.fromlist([text, label], fields)
  watermark_instance_irrelevant.append(example)
watermark_list['instance_irrelevant'] = watermark_instance_irrelevant

with open("/content/drive/My Drive/cs281_final_project/imdb_watermark.pkl","wb") as f:
    pickle.dump(watermark_list,f)